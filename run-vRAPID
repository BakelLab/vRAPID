#!/bin/bash

# 04.12.2023 11:17:27 EDT

########################################
# DEFINE GLOBAL ENVIRONMENT PARAMETERS #
########################################

# For all snakemake based pipelines we will at least need to know the location of the
# repository itself, as well as a per-user central conda environment work directory.
# If we do not specify the latter, the conda environments cannot easily be reused
# between jobs and a new environment will be created in each folder that the pipeline
# runs in. These would then need to be cleared manually each time.

# Set path to parent dir for conda environment work directory and git repositories
# Also pick up on the number of CPUs defined in jobstatus
CONDA_WORKDIR="${CONDA_WORKDIR:=/sc/arion/work/$USER/snakemake}"
GIT_REPODIR="${GIT_REPODIR:=$HOME/opt/vRAPID}"
JOB_NCPUS="${JOB_NCPUS:=16}"

# Make sure the repository exists and has a Snakefile at the expected location
if [[ ! -f "${GIT_REPODIR}/workflow/Snakefile" ]]
then
   echo "Error: could not find the Snakemake file in the defined repository location:\n  ${GIT_REPODIR}"
   exit 2
fi

# Create the conda environment work directory if it doesn't already exist
if [[ ! -d "${CONDA_WORKDIR}" ]]
then
   mkdir -p "${CONDA_WORKDIR}"
fi

# Make sure we have a conda environment work directory at this point (the directory creation could have failed)
if [[ ! -d "${CONDA_WORKDIR}" ]]
then
   echo "Error: could not find the conda environment work directory at the defined location:\n  ${CONDA_WORKDIR}"
   exit 2
fi

# Export environment parameters
export CONDA_WORKDIR
export GIT_REPODIR
export JOB_NCPUS

############################
# PROCESS COMMANDLINE ARGS #
############################

# Process command line arguments
RUN_ID=""
RUN_PATH=""
DEBUG=""

while getopts "i:p:D" opt; do
   case $opt in
   
   i) RUN_ID="run_id=$OPTARG"
      ;;
      
  p) RUN_PATH="path=$OPTARG"
      ;; 
  D)
      DEBUG="-p -n"
      ;;
   *)
      echo "Incorrect options provided"
      exit 1
      ;;

   esac
done

# Check arguments and display a help message if the required arguments are not found
if [ -z "$RUN_ID" ];
then
  cat << EOF

   Usage: run-vRAPID [ -D ] -i <run-id> -p <run-path>

   Arguments:
    -i <string>
      Run identifier
    -p <string>
      Path to the Run directory
    -D 
      Run pipeline in debug mode to show the commands that will be executed.
    -help
      This help message

EOF
  exit 0
fi

############################
# PREPARE THE JOB LOG FILE #
############################

# Here we write to a general log file for the pipeline that is timestamped
# to the start of the run. When run on the cluster, the LSF job ID is also
# added to the pipeline log file name.

# Write basic analysis parameters to a log file
timestamp="$(date +"%F_%H-%M-%S")"
if [ -n "$LSB_JOBID" ]
then
   timestamp="${timestamp}_lsf${LSB_JOBID}"
fi
echo "## Starting vRAPID assembly with the following parameters:"               > pipeline_${timestamp}.log
echo "   ${RUN_ID} ${RUN_PATH} "  >> pipeline_${timestamp}.log

# Generate a random name for the jobs
JOBNAME=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 5 | head -n 1)

#################################
# PREPARE SNAKEMAKE ENVIRONMENT #
#################################

# Load snakemake conda environment on chimera
module purge all
unset PYTHONPATH
unset PERL5LIB
unset R_LIBS
module load anaconda2
source activate snakemake

# Additional module load commands. Guppy needs to be pre-installed on the system
# as it is not available through conda or otherwise. We also need to load the 'proxies'
# module to set the http_proxy and https_proxy environment variables. Finally,
# we need the singularity module as installed on the cluster to enable user environments.
# This then provide support for e.g. docker containers.
#module load singularity/3.6.4
#module load proxies

# Add the bin folder with any external scripts that may be called from the pipeline to the path
export PATH="$GIT_REPODIR/bin/:$PATH"
export RUN_ID
export RUN_PATH

############################
# START SNAKEMAKE PIPELINE #
############################
# Prepare the snakemake command with support for conda and docker (singularity) environments

cmd="snakemake \
    ${DEBUG} \
    --use-singularity \
    --use-conda \
    --conda-frontend mamba \
    --conda-prefix   ${CONDA_WORKDIR} \
    --snakefile      ${GIT_REPODIR}/workflow/Snakefile \
    --cores          ${JOB_NCPUS} \
    --config         ${RUN_ID} ${RUN_PATH}"

# Make sure the exact command that was run ends up in the pipeline log
echo -e "\n## Run command\n$cmd\n\n## Pipeline output" >> pipeline_${timestamp}.log

# Run pipeline
$cmd >>  pipeline_${timestamp}.log 2>&1

# Check if the pipeline completed without errors
if [ $? -eq 0 ]
 then
   sleep 5
   echo -e "\n#######################################\n# vRAPID PIPELINE ENDED SUCCESSFULLY #\n#######################################\n" >> pipeline_${timestamp}.log;
else
   sleep 5
   echo -e "\n#######################################\n# vRAPID PIPELINE ENDED WITH ERRORS #\n#######################################\n" >> pipeline_${timestamp}.log;
fi
